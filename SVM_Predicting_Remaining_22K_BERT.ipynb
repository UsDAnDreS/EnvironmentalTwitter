{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc626fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "tag_map['AS'] = wn.ADJ_SAT\n",
    "\n",
    "# filepath = \"finalized_8K_accounts.csv\"\n",
    "# filepath = \"UNLABELED_accounts_emojis_replaced.csv\"\n",
    "filepath = \"FINALIZED_Unlabeled_Data_ALL_Available_Descriptions_EMOJIS_UNCHANGED.csv\"\n",
    "hand_label = \"hand.label\"\n",
    "government = \"gov\"\n",
    "academia = \"acad\"\n",
    "tourBiz = \"tourbiz\"\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# df = df[((df[hand_label] == 'media') | (df[hand_label] == tourBiz) |(df[hand_label] == academia) | (df[hand_label] == government) | (\n",
    "#        df[hand_label] == 'other'))]\n",
    "\n",
    "df = df[['username', 'description']]  # keep only relevant columns\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_not_changed = ['media']\n",
    "\n",
    "\n",
    "def preprocessing(row):\n",
    "    if str(row) == \"nan\":\n",
    "        lemma = \"\"\n",
    "    else:\n",
    "        row = str(row).lower()\n",
    "        row = word_tokenize(row)  # tokenize\n",
    "        lemma = [lemmatizer.lemmatize(token, tag_map[tag[0]]) if token not in words_not_changed else token for\n",
    "                 token, tag in pos_tag(row)]  # lemmatization, depending on part-of-speech\n",
    "        lemma = [\"\" if re.search(r'\\b[0-9]+\\b\\s*', lem) else lem for lem in lemma]  # removing\n",
    "    return str(lemma)\n",
    "\n",
    "\n",
    "df['description_lemmatized'] = df['description'].apply(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b4d3f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14599, 3)\n",
      "(13242, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove all the empty descriptions\n",
    "print(df.shape)\n",
    "print(df[df['description_lemmatized'] != \"\"].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57a23e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13242, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove all the empty descriptions\n",
    "df = df[df['description_lemmatized'] != \"\"]\n",
    "print(df.shape)\n",
    "#df[hand_label]\n",
    "#print(df.shape)\n",
    "#df[df['description_lemmatized'] != \"\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7612c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-indexing the remaining observations\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2af8cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# print(type(df[['description_lemmatized']]))\n",
    "embeddings = model.encode(df['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a13dfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'SVM_BOW_unweighted_enhanced_model.pickle'\n",
    "filename = 'SVM_BERT_unweighted_enhanced_model_full(1, 2).pickle'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "X_test = embeddings\n",
    "\n",
    "bag_of_words_y_pred_test = loaded_model.predict(X_test)\n",
    "\n",
    "bag_of_words_y_pred_test\n",
    "\n",
    "pred_prob = loaded_model.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc1d7478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>0.009342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>other</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>other</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>other</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13242 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         0         1         2         3         4\n",
       "0      other  0.000585  0.001464  0.001155  0.992605  0.004191\n",
       "1      other  0.004342  0.000639  0.003219  0.982458  0.009342\n",
       "2      other  0.005846  0.015085  0.049567  0.928598  0.000904\n",
       "3      other  0.001891  0.001057  0.002662  0.994019  0.000370\n",
       "4      other  0.006474  0.001169  0.005799  0.983785  0.002772\n",
       "...      ...       ...       ...       ...       ...       ...\n",
       "13237  other  0.001823  0.010809  0.064314  0.785241  0.137813\n",
       "13238  other  0.007914  0.001513  0.048221  0.941749  0.000602\n",
       "13239  other  0.492738  0.001781  0.002790  0.502624  0.000067\n",
       "13240  other  0.012996  0.000962  0.000605  0.984303  0.001134\n",
       "13241  other  0.001773  0.010881  0.021937  0.965021  0.000388\n",
       "\n",
       "[13242 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob\n",
    "bag_of_words_y_pred_test\n",
    "pd.concat([pd.DataFrame(bag_of_words_y_pred_test), pd.DataFrame(pred_prob)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ae85ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13242, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbd3b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13242, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_df = pd.DataFrame(pred_prob, columns = ['acad_prob','gov_prob','media_prob','other_prob', 'tourbiz_prob'])\n",
    "\n",
    "bag_of_words_y_pred_test.size\n",
    "\n",
    "df['hand.label_simplified'] = bag_of_words_y_pred_test\n",
    "#df = df.drop(columns=['description_lemmatized'])\n",
    "df1 = pd.concat([df, pred_prob_df], axis=1)\n",
    "#df1 = pd.DataFrame(my_array, columns = ['acad_prob','gov_prob','media_prob','other_prob', 'tourbiz_prob'])\n",
    "\n",
    "df1\n",
    "df1.shape\n",
    "#pred_prob_df.shape\n",
    "#len(bag_of_words_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0141ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lemmatized</th>\n",
       "      <th>hand.label_simplified</th>\n",
       "      <th>acad_prob</th>\n",
       "      <th>gov_prob</th>\n",
       "      <th>media_prob</th>\n",
       "      <th>other_prob</th>\n",
       "      <th>tourbiz_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeChatNoire4</td>\n",
       "      <td>#VOTE BLUE 2022 ðŸŒŠðŸ‡ºðŸ‡¸ðŸŒŠ #BuyARepublicanToday! no ...</td>\n",
       "      <td>['#', 'vote', 'blue', '', 'ðŸŒŠðŸ‡ºðŸ‡¸ðŸŒŠ', '#', 'buyare...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SethPlatt</td>\n",
       "      <td>Creator Collector Cultivator Art Web3 ENS AI S...</td>\n",
       "      <td>['creator', 'collector', 'cultivator', 'art', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>0.009342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eco_voice</td>\n",
       "      <td>A non-partisan, independent, volunteer run org...</td>\n",
       "      <td>['a', 'non-partisan', ',', 'independent', ',',...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corn4Harvick</td>\n",
       "      <td>*Flo-Grown* ðŸ‡ºðŸ‡¸ ðŸ‡ºðŸ‡¸ Jesus sent me back to straig...</td>\n",
       "      <td>['*', 'flo-grown', '*', 'ðŸ‡ºðŸ‡¸', 'ðŸ‡ºðŸ‡¸', 'jesus', '...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>memorabiliaddy</td>\n",
       "      <td>Healthcare Professional * Dad to Two * MSU Alu...</td>\n",
       "      <td>['healthcare', 'professional', '*', 'dad', 'to...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>EvergreenZephyr</td>\n",
       "      <td>Wichita, Kansas, United (sic) States. Parody a...</td>\n",
       "      <td>['wichita', ',', 'kansa', ',', 'united', '(', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>johntfox</td>\n",
       "      <td>Madeleine &amp; Marin's Dad | Gin Enthusiast | Twe...</td>\n",
       "      <td>['madeleine', '&amp;', 'marin', \"'s\", 'dad', '|', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>SeGreene</td>\n",
       "      <td>Cranky former nurse and current plant patholog...</td>\n",
       "      <td>['cranky', 'former', 'nurse', 'and', 'current'...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>CherylLasse</td>\n",
       "      <td>Passionate about the environment, science and ...</td>\n",
       "      <td>['passionate', 'about', 'the', 'environment', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>jen_pic</td>\n",
       "      <td>ðŸš«socialism. Pay your debts, ALL OF THEM! Nothi...</td>\n",
       "      <td>['ðŸš«socialism', '.', 'pay', 'your', 'debt', ','...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13242 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username                                        description  \\\n",
       "0         LeChatNoire4  #VOTE BLUE 2022 ðŸŒŠðŸ‡ºðŸ‡¸ðŸŒŠ #BuyARepublicanToday! no ...   \n",
       "1            SethPlatt  Creator Collector Cultivator Art Web3 ENS AI S...   \n",
       "2            eco_voice  A non-partisan, independent, volunteer run org...   \n",
       "3         Corn4Harvick  *Flo-Grown* ðŸ‡ºðŸ‡¸ ðŸ‡ºðŸ‡¸ Jesus sent me back to straig...   \n",
       "4       memorabiliaddy  Healthcare Professional * Dad to Two * MSU Alu...   \n",
       "...                ...                                                ...   \n",
       "13237  EvergreenZephyr  Wichita, Kansas, United (sic) States. Parody a...   \n",
       "13238         johntfox  Madeleine & Marin's Dad | Gin Enthusiast | Twe...   \n",
       "13239         SeGreene  Cranky former nurse and current plant patholog...   \n",
       "13240      CherylLasse  Passionate about the environment, science and ...   \n",
       "13241          jen_pic  ðŸš«socialism. Pay your debts, ALL OF THEM! Nothi...   \n",
       "\n",
       "                                  description_lemmatized  \\\n",
       "0      ['#', 'vote', 'blue', '', 'ðŸŒŠðŸ‡ºðŸ‡¸ðŸŒŠ', '#', 'buyare...   \n",
       "1      ['creator', 'collector', 'cultivator', 'art', ...   \n",
       "2      ['a', 'non-partisan', ',', 'independent', ',',...   \n",
       "3      ['*', 'flo-grown', '*', 'ðŸ‡ºðŸ‡¸', 'ðŸ‡ºðŸ‡¸', 'jesus', '...   \n",
       "4      ['healthcare', 'professional', '*', 'dad', 'to...   \n",
       "...                                                  ...   \n",
       "13237  ['wichita', ',', 'kansa', ',', 'united', '(', ...   \n",
       "13238  ['madeleine', '&', 'marin', \"'s\", 'dad', '|', ...   \n",
       "13239  ['cranky', 'former', 'nurse', 'and', 'current'...   \n",
       "13240  ['passionate', 'about', 'the', 'environment', ...   \n",
       "13241  ['ðŸš«socialism', '.', 'pay', 'your', 'debt', ','...   \n",
       "\n",
       "      hand.label_simplified  acad_prob  gov_prob  media_prob  other_prob  \\\n",
       "0                     other   0.000585  0.001464    0.001155    0.992605   \n",
       "1                     other   0.004342  0.000639    0.003219    0.982458   \n",
       "2                     other   0.005846  0.015085    0.049567    0.928598   \n",
       "3                     other   0.001891  0.001057    0.002662    0.994019   \n",
       "4                     other   0.006474  0.001169    0.005799    0.983785   \n",
       "...                     ...        ...       ...         ...         ...   \n",
       "13237                 other   0.001823  0.010809    0.064314    0.785241   \n",
       "13238                 other   0.007914  0.001513    0.048221    0.941749   \n",
       "13239                 other   0.492738  0.001781    0.002790    0.502624   \n",
       "13240                 other   0.012996  0.000962    0.000605    0.984303   \n",
       "13241                 other   0.001773  0.010881    0.021937    0.965021   \n",
       "\n",
       "       tourbiz_prob  \n",
       "0          0.004191  \n",
       "1          0.009342  \n",
       "2          0.000904  \n",
       "3          0.000370  \n",
       "4          0.002772  \n",
       "...             ...  \n",
       "13237      0.137813  \n",
       "13238      0.000602  \n",
       "13239      0.000067  \n",
       "13240      0.001134  \n",
       "13241      0.000388  \n",
       "\n",
       "[13242 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f0ec6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'SVM_BERT_unweighted_UNLABELED_PREDICTED_accounts_W_PROBABILITIES_emojis_unchanged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce37dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea2422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
